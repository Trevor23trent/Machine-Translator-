{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d55bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Sentences:\n",
      " ['Thanks', 'Good', 'Enjoy', 'Fine', 'Congratulations', 'I hate you', 'I love you', 'I’m in love', 'I’m sorry', 'I’m so sorry', 'I’m yours', 'Thanks again', 'How are you', 'I am fine', 'Take care', 'I miss you', 'You’re nice', 'That’s terrible', 'That’s too bad', 'That’s too much', 'See you', 'Thank you', 'Thank you sir', 'Are you free', 'No problem', 'Get well soon', 'Very good', 'Well done', 'What’s up', 'I can’t hear you', 'I can’t stop', 'I know', 'Good bye', 'Good idea', 'Good luck', 'You are late', 'Who is next?', 'Who is she?', 'Who is that man?', 'Who built it?', 'They hurt', 'She got angry', 'She is a teacher', 'She is aggressive', 'She is attractive', 'She is beautiful', 'She is crying', 'She is happy', 'No way!', 'No worries', 'No, thank you', 'I’m so happy', 'I’m hungry', 'I’m able to run', 'I agree', 'I can swim', 'I can’t come', 'He got angry', 'He was alone', 'He was brave', 'He likes to swim', 'Don’t be angry', 'Don’t be sad', 'Don’t cry', 'Come in', 'Come on', 'Can you come?', 'Can I help?', 'Can I eat this?', 'Can I help you?', 'Can I see?', 'Are you going?', 'Are you hungry?', 'Are you mad?', 'Are you serious?', 'Are you sleeping?', 'Can you do this?', 'Can you help me?', 'Can you tell me?', 'Come on tomorrow', 'Come quickly', 'Could I help you?', 'Could you tell me?', 'Do not disturb!', 'Do you hear me?', 'Do you smoke?', 'Have you eaten?', 'Have you finished?', 'He can run fast', 'He began to run', 'He did not speak', 'His eyes are blue', 'His smile was good', 'How is your life?', 'How is your family?', 'I am a student', 'I am going to study', 'I am not a teacher', 'I am sorry', 'I believe you', 'I can do this job', 'I can run faster', 'I can’t believe it', 'It happens', 'It is new', 'It is a long story', 'It looks like an bird', 'It really takes time', 'It was really cheap', 'It was so noisy', 'It was very difficult', 'It wasn’t expensive', 'It wasn’t necessary', 'Let me check', 'Let me say', 'Let me see', 'May I come in?', 'May I help you?', 'May I join you?', 'May I speak?', 'May I eat this?', 'My father is tall', 'My sister has a job', 'My sister is famous', 'My wife is a doctor', 'No problem', 'No, I’ll eat later', 'Please come in', 'Please do that again', 'Please give me', 'She admired him', 'She avoids me', 'She came last', 'She goes to school', 'That house is big', 'That is a good idea', 'That is my book', 'That is my son', 'The dog is dead', 'The river is wide', 'There is no doubt', 'They are playing', 'They are pretty', 'They got married', 'They have few books', 'They stopped talking', 'This is my friend', 'This bird can’t fly', 'This decision is final', 'This is my book', 'This is my brother', 'This is my daughter', 'This is not a joke', 'This is surprising', 'This river is beautiful', 'This story is true', 'We are happy', 'Will it rain today?', 'Will you go on a trip?', 'Will she come?', 'Would you kill me?', 'Would you love me?', 'Would you come here?', 'You are a teacher', 'You are very beautiful', 'You are very brave', 'You broke the rules', 'You love me', 'you love me or not', 'You make me happy', 'You may go', 'You should sleep', 'You must study hard', 'Whose idea is this?', 'Thanks for your help', 'Thank you for coming', 'How about you', 'How is your family', 'How to Say', 'Good morning', 'Good afternoon', 'Good evening', 'Good night', 'Happy birthday', 'Happy Christmas', 'Happy new year', 'Good to see you', 'I don’t like it', 'I have no idea', 'I know everything', 'I know something', 'Thank you so much', 'Thanks a million', 'See you later', 'See you next week', 'See you next year', 'See you soon', 'See you tomorrow', 'Sweet dreams', 'I’m crazy about you', 'I’m crazy with you', 'Nice to meet you', 'It’s very cheap', 'Just a moment', 'Not necessarily', 'That’s a good deal', 'You’re beautiful', 'You’re very nice', 'You’re very smart', 'I really appreciate it', 'I really miss you', 'What is your name', 'Which is correct?', 'Will you please help me?', 'Will you stay at home?', 'Do you need anything?', 'Do you need this book?', 'Are you feeling better?', 'Are you writing a letter?', 'Come and see me now', 'Come with your family', 'I’m very busy this week', 'There is a lot of money', 'They are good people', 'We need some money', 'What is your destination?', 'What are you doing today?', 'What are you reading?', 'What can I do for you?', 'What is the problem?', 'What is the story?', 'What is your problem?', 'What was that noise?', 'When can we eat?', 'When do you study?', 'When was it finished?', 'How about your family', 'Do you understand?', 'Do you love me?', 'Don’t talk about work', 'How can I help you?', 'How deep is the lake?', 'I’m not disturbing you', 'I’m proud of my son', 'I’m sorry to disturb you', 'Is something wrong?', 'May I open the door?', 'Thanks for everything', 'This is very difficult', 'This is very important', 'Where are you from', 'Do you have any idea', 'I love you so much', 'I love you very much', 'I’m in love with you', 'I missed you so much', 'Let me think about it', 'Thank you very much', 'I can’t stop thinking', 'Will you stop talking?', 'Would you like to go?', 'Would you teach me?', 'Where is your room?', 'Where should we go?', 'Where is your house?', 'Please close the door', 'She agreed to my idea', 'That boy is intelligent', 'It was a very big room', 'He can swim very fast', 'He accepted my idea', 'They loved each other', 'When will you reach?', 'Where are you from?', 'Where are you going?', 'We love each other', 'We obeyed the rules', 'We started to walk', 'We will never agree', 'We can make change', 'We cook everyday', 'We enjoyed it', 'What about you?', 'What are you doing?', 'What did you say?', 'What do you need?', 'What do you think?', 'What do you want?', 'What happened?', 'What is that?', 'When was she born?', 'When will we arrive?', 'Where are you?', 'Where does it hurt?', 'Where is my book?', 'Where is the river?', 'Who broke this?', 'Why are you crying?', 'I can’t see anything', 'I disagree with you', 'I like it very much', 'I need more time', 'I want to sleep', 'I’m able to swim', 'I’m not a doctor', 'I’m taller than you', 'I’m very sad', 'Is he a teacher?', 'Is she married?', 'Is this book yours?', 'Let’s ask the teacher', 'Let’s go out and eat', 'Let’s go to a movie', 'His opinion was not accepted', 'His proposals were adopted at the meeting', 'How do you come to school?', 'If I had money, I could buy it', 'If you want a pencil, I’ll lend you one', 'If he comes, ask him to wait', 'If it rains, we will get wet', 'If I studied, I would pass the exam', 'My hair has grown too long', 'My mother is always at home', 'There are many fish in this lake', 'There are many problems to solve', 'There are some books on the desk', 'There is nothing wrong with him', 'There was a sudden change in the weather', 'There was nobody in the garden', 'There was nobody there', 'There were five murders this month', 'They admire each other', 'They agreed to work together', 'They are both good teachers', 'We want something new', 'We should be very careful', 'When can I see you next time?', 'When did you finish the work?', 'When will you harvest your wheat?', 'Where do you want to go?', 'Where is the pretty girl?', 'Which food do you like?', 'Which is more important?', 'Which one is more expensive?', 'Which way is the nearest?', 'Which is your favorite team?', 'Which languages do you speak?', 'Which team will win the game?', 'Why are you drying your hair?', 'Why are you late?', 'Why did you get so angry?', 'Why did you quit?', 'Why don’t you come in?', 'Why were you late this morning?', 'Why are you so tired today?', 'Would you like to dance with me?', 'Would you come tomorrow?', 'You are always complaining', 'Thanks for your explanation', 'Thanks for the compliment', 'Thanks for the information', 'Thanks for your understanding', 'Thank you for supporting me', 'I really miss you so much', 'Happy valentine’s day', 'Whose decision was final?', 'Whose life is in danger?', 'You are a good teacher', 'You can read this book', 'You don’t understand me', 'You have to study hard', 'Where do you have pain?', 'They are both in the room', 'That house is very small', 'Please give me your hand', 'Please go to the school', 'Please sit here and wait', 'Please speak more slowly', 'My father is in his room', 'May I ask you something?', 'May I ask you a question?', 'Is the job still available?', 'I arrived there too early', 'Do you have a family?', 'Do you have any problem?', 'Do you have any idea?', 'Did you finish the job?', 'Did you like the movie?', 'Are we ready to go now?', 'Would you like to come?', 'I don’t speak very well', 'Eat', 'All', 'New', 'Snore', 'Fast', 'Help', 'Pain', 'Rain', 'Pride', 'Sense', 'Large', 'Skill', 'Panic', 'Thank', 'Desire', 'Woman', 'Hungry']\n",
      "\n",
      "Swahili Sentences:\n",
      " ['Asante', 'Nzuri', 'Furahiya', 'Faini', 'Hongera', 'Nakuchukia', 'nakupenda', 'Nina mapenzi', 'Samahani', 'Samahani', 'Mimi ni wako', 'Asante tena', 'Habari yako', 'sijambo', 'Kuwa mwangalifu', 'ninakukosa rohoni', 'Wewe ni mzuri', 'Hiyo ni mbaya', 'Hiyo ni mbaya sana', 'Hiyo ni nyingi sana', 'Baadaye', 'Asante', 'Asante bwana', 'Je una wakati', 'Hakuna shida', 'Upone haraka', 'Vizuri sana', 'Umefanya vizuri', 'Vipi', 'Siwezi kukusikia', 'Siwezi kuacha', 'Najua', 'Kwaheri', 'Wazo nzuri', 'Bahati njema', 'umechelewa', 'nani anafuata?', 'yeye ni nani?', 'mwanaume huyo ni nani?', 'nani aliijenga?', 'wanaumia', 'alikasirika', 'yeye ni mwalimu', 'yeye ni mkali', 'anavutia', 'yeye ni mzuri', 'analia', 'amefurahi', 'Hapana!', 'hakuna wasiwasi', 'Hapana Asante', 'Nimefurahi sana', 'nina njaa', 'naweza kukimbia', 'nakubali', 'naweza kuogelea', 'siwezi kuja', 'alikasirika', 'alikuwa peke yake', 'alikuwa jasiri', 'anapenda kuogelea', 'usiwe na hasira', 'usiwe na huzuni', 'usilie', 'ingia', 'njoo', 'unaweza kuja?', 'naweza kusaidia?', 'naweza kula hii?', 'Naweza kukusaidia?', 'naweza kuona?', 'unakwenda?', 'una njaa?', 'unawazimu?', 'una uhakika?', 'umelala?', 'unaweza kufanya hivi?', 'unaweza kunisaidia?', 'unaweza kuniambia?', 'njoo kesho', 'njoo haraka', 'ningeweza kukusaidia?', 'unaweza kuniambia?', 'usisumbue!', 'unanisikia?', 'unavuta sigara?', 'umekula?', 'umemaliza?', 'anaweza kukimbia haraka', 'akaanza kukimbia', 'hakuzungumza', 'macho yake ni bluu', 'tabasamu lake lilikuwa zuri', 'maisha yako yakoje?', 'Familia yako ikoje?', 'Mimi ni mwanafunzi', 'naenda kusoma', 'mimi si mwalimu', 'Samahani', 'nakuamini', 'naweza kufanya kazi hii', 'naweza kukimbia kwa kasi', 'siwezi kuamini', 'inatokea', 'ni mpya', 'ni hadithi ndefu', 'inaonekana kama ndege', 'kweli inachukua muda', 'ilikuwa nafuu kweli', 'ilikuwa kelele sana', 'ilikuwa ngumu sana', 'haikuwa ghali', 'haikuwa lazima', 'wacha niangalie', 'ngoja niseme', 'Ngoja nione', 'naweza kuingia?', 'naweza kukusaidia?', 'naweza kujiunga nawe?', 'naweza kusema?', 'naweza kula hii?', 'baba yangu ni mrefu', 'dada yangu ana kazi', 'dada yangu ni maarufu', 'mke wangu ni daktari', 'hakuna shida', 'hapana, nitakula baadaye', 'tafadhali ingia', 'tafadhali fanya hivyo tena', 'tafadhali nipe', 'yeye admired yake', 'ananiepuka', 'alikuja mwisho', 'anaenda shule', 'hiyo nyumba ni kubwa', 'hilo ni wazo zuri', 'hicho ni kitabu changu', 'huyo ni mwanangu', 'mbwa amekufa', 'mto ni mpana', 'hamna shaka', 'wanacheza', 'wao ni wazuri', 'walifunga ndoa', 'wana vitabu vichache', 'wakaacha kuongea', 'huyu ni rafiki yangu', 'ndege huyu hawezi kuruka', 'uamuzi huu ni wa mwisho', 'Hiki ni kitabu changu', 'huyu ni ndugu yangu', 'huyu ni binti yangu', 'huu si mzaha', 'hii inashangaza', 'mto huu ni mzuri', 'hadithi hii ni kweli', 'tuna furaha', 'itanyesha leo?', 'utaenda safari?', 'atakuja?', 'ungeniua?', 'ungenipenda?', 'ungekuja hapa?', 'wewe ni mwalimu', 'wewe ni mrembo sana', 'wewe ni jasiri sana', 'umevunja sheria', 'unanipenda', 'unanipenda au hunipendi', 'unanifurahisha', 'unaweza kwenda', 'unapaswa kulala', 'lazima usome kwa bidii', 'wazo hili ni la nani?', 'Shukrani kwa msaada wako', 'asante kwa kuja', 'Je wewe', 'Familia yako ikoje', 'Jinsi ya Kusema', 'Habari za asubuhi', 'Mchana mwema', 'Habari za jioni', 'Usiku mwema', 'Heri ya siku ya kuzaliwa', 'Krismasi njema', 'Heri ya mwaka mpya', 'Nzuri kukuona', 'Sipendi', 'sijui', 'najua kila kitu', 'Najua kitu', 'Asante sana', 'Asante milioni', 'Tutaonana baadaye', 'Tutaonana wiki ijayo', 'Tukutane mwakani', 'Nitakuona hivi karibuni', 'Tuonane kesho', 'Ndoto nzuri', 'Nina wazimu juu yako', 'Nina wazimu na wewe', 'Ninafurahi kukutana nawe', 'Ni rahisi sana', 'Ngoja kidogo', 'Sio lazima', 'Huo ni mpango mzuri', 'Wewe ni mrembo', 'Wewe ni mzuri sana', 'Wewe ni mwerevu sana', 'Ninathamini sana', 'Nimekukosa sana', 'Jina lako nani', 'ipi ni sahihi?', 'utanisaidia tafadhali?', 'utakaa nyumbani?', 'unahitaji chochote?', 'unahitaji kitabu hiki?', 'unajisikia vizuri?', 'unaandika barua?', 'njoo unione sasa', 'njoo na familia yako', 'nina shughuli nyingi sana wiki hii', 'kuna pesa nyingi', 'ni watu wema', 'tunahitaji pesa', 'unaenda wapi?', 'unafanya nini leo?', 'unasoma nini?', 'naweza kukusaidia vipi?', 'shida ni nini?', 'hadithi ni nini?', 'shida yako ni ipi?', 'kelele gani hiyo?', 'tunaweza kula lini?', 'unasoma lini?', 'ilikamilika lini?', 'Vipi kuhusu familia yako', 'unaelewa?', 'Unanipenda?', 'usizungumze juu ya kazi', 'Nikusaidie vipi?', 'ziwa lina kina kipi?', 'sikusumbui', 'najivunia mwanangu', 'samahani kwa kukusumbua', 'kuna kitu kibaya?', 'naweza kufungua mlango?', 'Asante kwa kila kitu', 'Hii ni ngumu sana', 'Hii ni muhimu sana', 'Unatoka wapi', 'Je! Una wazo lolote', 'nakupenda sana', 'nakupenda sana', 'Ninakupenda', 'Nimekukosa sana', 'Ngoja nifikirie juu yake', 'Asante sana', 'Siwezi kuacha kufikiria', 'utaacha kuongea?', 'Ungependa kwenda?', 'ungenifundisha?', 'chumba chako kiko wapi?', 'twende wapi?', 'nyumba yako iko wapi?', 'tafadhali funga mlango', 'alikubali wazo langu', 'huyo kijana ana akili', 'kilikuwa ni chumba kikubwa sana', 'anaweza kuogelea haraka sana', 'alikubali wazo langu', 'walipendana', 'utafikia lini?', 'Unatoka wapi?', 'unaenda wapi?', 'tunapendana', 'tulitii sheria', 'tulianza kutembea', 'hatutakubali kamwe', 'tunaweza kufanya mabadiliko', 'tunapika kila siku', 'tulifurahia', 'Na wewe je?', 'unafanya nini?', 'ulisema nini?', 'unahitaji nini?', 'nini unadhani; unafikiria nini?', 'Unataka nini?', 'Nini kimetokea?', 'hiyo ni nini?', 'alizaliwa lini?', 'tutafika lini?', 'uko wapi?', 'inauma wapi?', 'kitabu changu kiko wapi?', 'mto uko wapi?', 'nani alivunja hii?', 'kwa nini unalia?', 'sioni chochote', 'sikubaliani na wewe', 'naipenda sana', 'nahitaji muda zaidi', 'nataka kulala', 'naweza kuogelea', 'mimi sio daktari', 'mimi ni mrefu kuliko wewe', 'nina huzuni sana', 'yeye ni mwalimu?', 'ameolewa?', 'kitabu hiki ni chako?', 'tumuulize mwalimu', 'twende tukale', 'twende kwenye sinema', 'maoni yake hayakukubaliwa', 'mapendekezo yake yalipitishwa katika mkutano huo', 'unakujaje shule?', 'kama ningekuwa na pesa, ningeweza kuinunua', 'ukitaka penseli, nitakuazima', 'akija, mwambie asubiri', 'mvua ikinyesha tutalowa', 'ikiwa nilisoma, ningefaulu mtihani', 'nywele zangu zimekua ndefu sana', 'mama yangu yuko nyumbani kila wakati', 'kuna samaki wengi katika ziwa hili', 'kuna matatizo mengi ya kutatua', 'kuna baadhi ya vitabu kwenye dawati', 'hakuna kitu kibaya kwake', 'kulikuwa na mabadiliko ya ghafla ya hali ya hewa', 'hakukuwa na mtu kwenye bustani', 'hapakuwa na mtu', 'kulikuwa na mauaji matano mwezi huu', 'wanashangaana', 'walikubaliana kufanya kazi pamoja', 'wote wawili ni walimu wazuri', 'tunataka kitu kipya', 'tunapaswa kuwa makini sana', 'nitakuona lini wakati mwingine?', 'ulimaliza kazi lini?', 'lini utavuna ngano yako?', 'Unataka kwenda wapi?', 'msichana mrembo yuko wapi?', 'unapenda chakula gani?', 'lipi lililo muhimu zaidi?', 'ipi ni ghali zaidi?', 'ni njia gani iliyo karibu zaidi?', 'ni timu gani unayoipenda zaidi?', 'unazungumza lugha gani?', 'ni timu gani itashinda mchezo huo?', 'kwa nini unakausha nywele?', 'kwa nini umechelewa?', 'mbona umekasirika sana?', 'kwa nini uliacha?', 'kwanini usiingie?', 'mbona umechelewa asubuhi hii?', 'mbona leo umechoka sana?', 'ungependa kucheza nami?', 'ungekuja kesho?', 'unalalamika kila mara', 'asante kwa maelezo yako', 'asante kwa pongezi', 'asante kwa taarifa', 'asante kwa ufahamu wako', 'asante kwa kuniunga mkono', 'Nimekukosa sana', 'Siku njema ya wapendanao', 'uamuzi wa nani ulikuwa wa mwisho?', 'maisha ya nani yako hatarini?', 'wewe ni mwalimu mzuri', 'unaweza kusoma kitabu hiki', 'hunielewi', 'inabidi usome kwa bidii', 'una maumivu wapi?', 'wote wawili wako chumbani', 'hiyo nyumba ni ndogo sana', 'tafadhali nipe mkono wako', 'tafadhali nenda shule', 'tafadhali keti hapa na usubiri', 'tafadhali zungumza polepole zaidi', 'baba yangu yuko chumbani kwake', 'naweza kukuuliza kitu?', 'naweza kukuuliza swali?', 'kazi bado ipo?', 'nilifika hapo mapema sana', 'una familia?', 'una tatizo lolote?', 'una wazo lolote?', 'umemaliza kazi?', 'ulipenda filamu?', 'tuko tayari kwenda sasa?', 'ungependa kuja?', 'Sisemi vizuri sana', 'kula', 'zote', 'mpya', 'koroma', 'haraka', 'msaada', 'maumivu', 'mvua', 'kiburi', 'maana', 'kubwa', 'ujuzi', 'wasiwasi', 'asante', 'hamu', 'mwanamke', 'njaa']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.learnentry.com/english-to-swahili/swahili-sentences-and-phrases/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "english_sentences = []\n",
    "swahili_sentences = []\n",
    "\n",
    "for row in soup.find_all('tr')[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 2:  # Add this condition to check if there are two columns in the row\n",
    "        english_sentence = cols[0].get_text().strip()\n",
    "        swahili_sentence = cols[1].get_text().strip()\n",
    "        english_sentences.append(english_sentence)\n",
    "        swahili_sentences.append(swahili_sentence)\n",
    "    \n",
    "print(\"English Sentences:\\n\", english_sentences)\n",
    "print(\"\\nSwahili Sentences:\\n\", swahili_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b662c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code after preprocessing which involves converting to lower case\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.learnentry.com/english-to-swahili/swahili-sentences-and-phrases/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "english_sentences = []\n",
    "swahili_sentences = []\n",
    "\n",
    "for row in soup.find_all('tr')[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 2:\n",
    "        english_sentence = cols[0].get_text().strip()\n",
    "        swahili_sentence = cols[1].get_text().strip()\n",
    "        english_sentences.append(english_sentence)\n",
    "        swahili_sentences.append(swahili_sentence)\n",
    "    \n",
    "data = {'English': english_sentences, 'Swahili': swahili_sentences}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing the data\n",
    "df['English'] = df['English'].apply(lambda x: x.lower())\n",
    "df['Swahili'] = df['Swahili'].apply(lambda x: x.lower())\n",
    "\n",
    "# Save to CSV file\n",
    "df.to_csv('sentences.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "530ad1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             English   Swahili\n",
      "0             thanks    asante\n",
      "1               good     nzuri\n",
      "2              enjoy  furahiya\n",
      "3               fine     faini\n",
      "4    congratulations   hongera\n",
      "..               ...       ...\n",
      "403            panic  wasiwasi\n",
      "404            thank    asante\n",
      "405           desire      hamu\n",
      "406            woman  mwanamke\n",
      "407           hungry      njaa\n",
      "\n",
      "[408 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28321b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English Features:\n",
      "   (0, 331)\t1.0\n",
      "  (1, 140)\t1.0\n",
      "  (2, 103)\t1.0\n",
      "  (3, 121)\t1.0\n",
      "  (4, 65)\t1.0\n",
      "  (5, 385)\t0.31845540198385114\n",
      "  (5, 152)\t0.9479378444535822\n",
      "  (6, 195)\t0.9084838108765929\n",
      "  (6, 385)\t0.41792004662990595\n",
      "  (7, 168)\t0.6939574514539055\n",
      "  (7, 195)\t0.7200160106355972\n",
      "  (8, 301)\t1.0\n",
      "  (9, 295)\t0.6571121287869782\n",
      "  (9, 301)\t0.7537928430285379\n",
      "  (10, 387)\t1.0\n",
      "  (11, 7)\t0.7822185632371257\n",
      "  (11, 331)\t0.6230041085957995\n",
      "  (12, 21)\t0.55344351637931\n",
      "  (12, 162)\t0.7566640936834965\n",
      "  (12, 385)\t0.34808005330360026\n",
      "  (13, 14)\t0.6618173825605836\n",
      "  (13, 121)\t0.7496650933187821\n",
      "  (14, 53)\t0.7071067811865475\n",
      "  (14, 317)\t0.7071067811865475\n",
      "  (15, 208)\t0.9356120976397049\n",
      "  :\t:\n",
      "  (389, 189)\t0.533576224263735\n",
      "  (389, 60)\t0.463120675918879\n",
      "  (389, 341)\t0.4160516395147877\n",
      "  (389, 385)\t0.2352288682684165\n",
      "  (390, 302)\t0.5267466893624159\n",
      "  (390, 93)\t0.48584680124440194\n",
      "  (390, 352)\t0.4053001036775977\n",
      "  (390, 362)\t0.5676465774804298\n",
      "  (391, 101)\t1.0\n",
      "  (392, 11)\t1.0\n",
      "  (393, 227)\t1.0\n",
      "  (394, 294)\t1.0\n",
      "  (395, 114)\t1.0\n",
      "  (396, 156)\t1.0\n",
      "  (397, 247)\t1.0\n",
      "  (398, 263)\t1.0\n",
      "  (399, 255)\t1.0\n",
      "  (400, 279)\t1.0\n",
      "  (401, 181)\t1.0\n",
      "  (402, 286)\t1.0\n",
      "  (403, 248)\t1.0\n",
      "  (404, 330)\t1.0\n",
      "  (405, 80)\t1.0\n",
      "  (406, 378)\t1.0\n",
      "  (407, 163)\t1.0\n",
      "\n",
      "Swahili Features:\n",
      "   (0, 22)\t1.0\n",
      "  (1, 319)\t1.0\n",
      "  (2, 53)\t1.0\n",
      "  (3, 47)\t1.0\n",
      "  (4, 86)\t1.0\n",
      "  (5, 271)\t1.0\n",
      "  (6, 272)\t1.0\n",
      "  (7, 214)\t0.7801848910750913\n",
      "  (7, 296)\t0.6255489874807153\n",
      "  (8, 331)\t1.0\n",
      "  (9, 331)\t1.0\n",
      "  (10, 456)\t0.6570770659340521\n",
      "  (10, 288)\t0.369458331678952\n",
      "  (10, 227)\t0.6570770659340521\n",
      "  (11, 360)\t0.8166337199298191\n",
      "  (11, 22)\t0.5771562764742193\n",
      "  (12, 482)\t0.6201650113552128\n",
      "  (12, 57)\t0.7844713880638278\n",
      "  (13, 343)\t1.0\n",
      "  (14, 254)\t0.7301380726917892\n",
      "  (14, 181)\t0.6832996376450959\n",
      "  (15, 328)\t0.7071067811865475\n",
      "  (15, 298)\t0.7071067811865475\n",
      "  (16, 261)\t0.6932356824046291\n",
      "  (16, 477)\t0.5984186249093653\n",
      "  :\t:\n",
      "  (388, 363)\t0.5265425091894625\n",
      "  (388, 334)\t0.49276475120312596\n",
      "  (388, 188)\t0.4502098088720977\n",
      "  (389, 431)\t0.7212622382562573\n",
      "  (389, 155)\t0.6926620991981399\n",
      "  (390, 352)\t0.7009132540184744\n",
      "  (390, 451)\t0.5993020822066848\n",
      "  (390, 333)\t0.38672680874742277\n",
      "  (391, 164)\t1.0\n",
      "  (392, 493)\t1.0\n",
      "  (393, 235)\t1.0\n",
      "  (394, 143)\t1.0\n",
      "  (395, 70)\t1.0\n",
      "  (396, 238)\t1.0\n",
      "  (397, 219)\t1.0\n",
      "  (398, 245)\t1.0\n",
      "  (399, 130)\t1.0\n",
      "  (400, 203)\t1.0\n",
      "  (401, 147)\t1.0\n",
      "  (402, 384)\t1.0\n",
      "  (403, 469)\t1.0\n",
      "  (404, 22)\t1.0\n",
      "  (405, 65)\t1.0\n",
      "  (406, 251)\t1.0\n",
      "  (407, 311)\t1.0\n"
     ]
    }
   ],
   "source": [
    "#In this updated code, I have added the TfidfVectorizer class from scikit-learn library to extract features using the TF-IDF technique\n",
    "#updated code with feature extraction\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "url = \"https://www.learnentry.com/english-to-swahili/swahili-sentences-and-phrases/\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "english_sentences = []\n",
    "swahili_sentences = []\n",
    "\n",
    "for row in soup.find_all('tr')[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 2:\n",
    "        english_sentence = cols[0].get_text().strip()\n",
    "        swahili_sentence = cols[1].get_text().strip()\n",
    "        english_sentences.append(english_sentence)\n",
    "        swahili_sentences.append(swahili_sentence)\n",
    "    \n",
    "data = {'English': english_sentences, 'Swahili': swahili_sentences}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing the data\n",
    "df['English'] = df['English'].apply(lambda x: x.lower())\n",
    "df['Swahili'] = df['Swahili'].apply(lambda x: x.lower())\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_english = tfidf.fit_transform(df['English'])\n",
    "X_swahili = tfidf.fit_transform(df['Swahili'])\n",
    "\n",
    "print(\"English Features:\\n\", X_english)\n",
    "print(\"\\nSwahili Features:\\n\", X_swahili)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4cc3704",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "3/3 [==============================] - 7s 678ms/step - loss: 6.0212 - accuracy: 0.3810 - val_loss: 5.8942 - val_accuracy: 0.8157\n",
      "Epoch 2/100\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 5.8605 - accuracy: 0.7045 - val_loss: 5.5883 - val_accuracy: 0.8184\n",
      "Epoch 3/100\n",
      "3/3 [==============================] - 1s 175ms/step - loss: 5.5208 - accuracy: 0.7045 - val_loss: 4.7924 - val_accuracy: 0.8184\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 174ms/step - loss: 4.6266 - accuracy: 0.7045 - val_loss: 3.3344 - val_accuracy: 0.8184\n",
      "Epoch 5/100\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 3.2965 - accuracy: 0.7045 - val_loss: 2.3836 - val_accuracy: 0.8184\n",
      "Epoch 6/100\n",
      "3/3 [==============================] - 0s 170ms/step - loss: 2.5064 - accuracy: 0.7045 - val_loss: 1.8710 - val_accuracy: 0.8184\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 140ms/step - loss: 2.1937 - accuracy: 0.7045 - val_loss: 1.6118 - val_accuracy: 0.8184\n",
      "Epoch 8/100\n",
      "3/3 [==============================] - 0s 147ms/step - loss: 2.1238 - accuracy: 0.7045 - val_loss: 1.4872 - val_accuracy: 0.8184\n",
      "Epoch 9/100\n",
      "3/3 [==============================] - 0s 142ms/step - loss: 2.1267 - accuracy: 0.7045 - val_loss: 1.4278 - val_accuracy: 0.8184\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 2.1278 - accuracy: 0.7045 - val_loss: 1.4002 - val_accuracy: 0.8184\n",
      "Epoch 11/100\n",
      "3/3 [==============================] - 0s 145ms/step - loss: 2.0914 - accuracy: 0.7045 - val_loss: 1.3847 - val_accuracy: 0.8184\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 138ms/step - loss: 2.0250 - accuracy: 0.7045 - val_loss: 1.3803 - val_accuracy: 0.8184\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 164ms/step - loss: 1.9496 - accuracy: 0.7045 - val_loss: 1.3925 - val_accuracy: 0.8171\n",
      "Epoch 14/100\n",
      "3/3 [==============================] - 0s 143ms/step - loss: 1.9006 - accuracy: 0.7055 - val_loss: 1.4198 - val_accuracy: 0.8171\n",
      "Epoch 15/100\n",
      "3/3 [==============================] - 0s 153ms/step - loss: 1.8753 - accuracy: 0.7035 - val_loss: 1.4497 - val_accuracy: 0.8171\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 171ms/step - loss: 1.8692 - accuracy: 0.7048 - val_loss: 1.4654 - val_accuracy: 0.8171\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 1.8611 - accuracy: 0.7048 - val_loss: 1.4637 - val_accuracy: 0.8171\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.4637 - accuracy: 0.8171\n",
      "Test set accuracy: 81.71%\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LSTM, Embedding\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load the data\n",
    "url = \"https://www.learnentry.com/english-to-swahili/swahili-sentences-and-phrases/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "english_sentences = []\n",
    "swahili_sentences = []\n",
    "for row in soup.find_all('tr')[1:]:\n",
    "    cols = row.find_all('td')\n",
    "    if len(cols) == 2:\n",
    "        english_sentence = cols[0].get_text().strip()\n",
    "        swahili_sentence = cols[1].get_text().strip()\n",
    "        english_sentences.append(english_sentence)\n",
    "        swahili_sentences.append(swahili_sentence)\n",
    "data = {'English': english_sentences, 'Swahili': swahili_sentences}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Preprocessing the data\n",
    "df['English'] = df['English'].apply(lambda x: x.lower())\n",
    "df['Swahili'] = df['Swahili'].apply(lambda x: x.lower())\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_sentences, test_sentences, train_targets, test_targets = train_test_split(df['English'], df['Swahili'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenize the input and output sequences\n",
    "input_tokenizer = Tokenizer()\n",
    "input_tokenizer.fit_on_texts(train_sentences)\n",
    "train_sequences = input_tokenizer.texts_to_sequences(train_sentences)\n",
    "test_sequences = input_tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "output_tokenizer = Tokenizer()\n",
    "output_tokenizer.fit_on_texts(train_targets)\n",
    "train_targets_sequences = output_tokenizer.texts_to_sequences(train_targets)\n",
    "test_targets_sequences = output_tokenizer.texts_to_sequences(test_targets)\n",
    "\n",
    "# Get the maximum sequence length for padding\n",
    "max_seq_len_input = max(len(sequence) for sequence in train_sequences)\n",
    "max_seq_len_output = max(len(sequence) for sequence in train_targets_sequences)\n",
    "max_seq_len = max(max_seq_len_input, max_seq_len_output)\n",
    "\n",
    "# Pad the input and output sequences\n",
    "train_sequences_padded = pad_sequences(train_sequences, maxlen=max_seq_len, padding='post')\n",
    "test_sequences_padded = pad_sequences(test_sequences, maxlen=max_seq_len, padding='post')\n",
    "\n",
    "train_targets_sequences_padded = pad_sequences(train_targets_sequences, maxlen=max_seq_len, padding='post')\n",
    "test_targets_sequences_padded = pad_sequences(test_targets_sequences, maxlen=max_seq_len, padding='post')\n",
    "\n",
    "# Convert the output sequences to one-hot encoding\n",
    "train_targets_onehot = to_categorical(train_targets_sequences_padded, num_classes=len(output_tokenizer.word_index)+1)\n",
    "test_targets_onehot = to_categorical(test_targets_sequences_padded, num_classes=len(output_tokenizer.word_index)+1)\n",
    "\n",
    "#Define the model architecture\n",
    "input_shape = (max_seq_len,)\n",
    "output_shape = (max_seq_len, len(output_tokenizer.word_index)+1)\n",
    "input_layer = Input(shape=input_shape)\n",
    "embedding_layer = Embedding(input_dim=len(input_tokenizer.word_index)+1, output_dim=256)(input_layer)\n",
    "lstm_layer = LSTM(256, return_sequences=True)(embedding_layer)\n",
    "output_layer = Dense(len(output_tokenizer.word_index)+1, activation='softmax')(lstm_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "#Compile the model\n",
    "optimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
    "history = model.fit(train_sequences_padded, train_targets_onehot, validation_data=(test_sequences_padded, test_targets_onehot), batch_size=128, epochs=100, callbacks=[early_stopping])\n",
    "\n",
    "#Evaluate the model on the test set\n",
    "loss, accuracy = model.evaluate(test_sequences_padded, test_targets_onehot)\n",
    "print(\"Test set accuracy: {:.2f}%\".format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a792b081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
